% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knn.r
\name{knn}
\alias{knn}
\title{knn}
\usage{
knn(x, y, test, k = 1)
}
\arguments{
\item{x}{The training data, stored as a numeric matrix or dataframe.}

\item{y}{Labels for the training data, stored as an integer or factor.}

\item{test}{New data to be classified.  Must have the same number of columns as the input
\code{x}.}

\item{k}{The eponymous 'k', i.e., the number of voters involved in classification.}
}
\value{
The classified labels of
}
\description{
k-nearest neighbors.
}
\details{
At the moment, ties are resolved by choosing the smallest index.  I may
eventually implement a better one (say random voting).

The implementation is cache-aware and uses threads, and should be reasonably
fast.
}
\examples{
\dontrun{
train_ind = 1:25
x = rbind(
  subset(iris, Species=='setosa')[train_ind, ],
  subset(iris, Species=='versicolor')[train_ind, ],
  subset(iris, Species=='virginica')[train_ind, ]
)

test_ind = 26:50
test = rbind(
  subset(iris, Species=='setosa')[test_ind, ],
  subset(iris, Species=='versicolor')[test_ind, ],
  subset(iris, Species=='virginica')[test_ind, ]
)

x$Species = NULL
test$Species = NULL

y <- factor(c(rep("s", 25), rep("c", 25), rep("v", 25)))

k = 3
knn::knn(train, cl, test, k=k)
}

}
